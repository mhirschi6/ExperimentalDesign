Decisions

what measurement to make (the response)
what conditions to study(the treatments)
what experimental material too use (the units)


 Variability
 
 variability due to condtions of interest (wanted)
 variability in the measurement process(unwanted)
 variability in the experimental material and process(unwanted)
 
 
  Kinds of Variability
  
  planned systematic variability- the kind we want 
  chance-like variability- the kinds we can live with
  unplanned, systematic variability- the kind that Threatens Disaster
  
    
  
  Bias - An effect that deprives a statistic or observation of representativeness by systematically distorting it. 
  Contrast with the random error which may distort on any one occasion, but balance out on average. 
  
  
  Decisions
  
  What measurement to make. what conditions to compare and what material to use 
  
  Analysis of variance is :
    impossible for nominal data. 
  sometimes appropriate for ordinal data, but at the risk of losing information.
  generally appropriate for interval and ratio data.
  
  additonal options for choice of response:
    interval and ratio data: change in measurement.
  ration data: perceent change in measurement.
  
  
  
  
  Stevens four types
  
  the weight of a thyroid gland. ratio
  the body temperature of mouse. interval or ratio
  a very rough psychiatric classification with four categories, 
  normal/neurotic/borderline/psychotic. ordinal. 
  the genotype a plant, animal, or human. nominal.
  
  
reliability and validity

reliability and validity both refer to the soundness of the connections between 
the gaol of an experiment and your choice of response, that is, between the 
kinds of conclusions you hope to draw and the kind of evidence you plan to gather. 


  Reliability is concerned with repeatability.
  Validity is concerned with relevance. 
  
  
  Experimental you start with one set of subjects or material to which you 
  assign treatments(the conditions yu want to compare)
  
  Observational you start with several populations of subjects or 
  objects(with the condtions already built in) you take samples from populations.
  
  
  Experment compares treatments
  Observational compares populations
  
  
  
  Control group -  a bench mark or reference group, often 
  representing the status quo
  
  Confouding - Two influences on the response are confounded if the design makes 
  it impossible to isolate the effects of one of the effects vs. another effect.
  
  Selection bias - sample selection method ruins your ability to isolate 
  the effects of interest. 
  
   
  
  
  three design principles. 
  
  random assignment, blocking, factorial crossing. 
  
  Observed number = true value + residual error
  
  The unknown true values are Constant. The pieces that go together to make the 
  observed value are combined by adding them not by some other process such as 
  mulitplying. 
  
  
  Randomize whenever you can. 
  
  response - the output of a process or experiment that is measured for analysis.
  Factor - variable that can cause changes in the output. experimental factors 
  are manipulated by the researcher.
  treatment - a combination of factor levels whose effect is compared with 
  other treatments.
  experimental unit - the chunk of experimental material that is assigned a 
  treatment. 
  
  Blocking - converts unplanned systematic variation into planned, systematic 
  variation.
  involves restrictred randomization to control for known nuisance factors.
  good strategy if you can sort your experimental material into groups of units
  that are:
    similar within groups
    different across groups. 
    
  replication - an independent repeat of an experimental conditions so that
  variability can be estimated.
  
  RBF- randomly assign treatments to the experimental units 
  good choice for your design if the experimetnal material is reasonably uniform.
  One-Way anova
  
  One Way complete Block- block by like causes. 
  
  Two-Way bsaic factorial design - same as RBF but with two factorials. 
  
  if the results above are stastically significant, we say there is a signficant 
  interaction and use caustion when interpreting the main effect. 
  in additition to the main effects and the interaction, this and every design 
  will have an effect or factor due to the overall grand mean and the residual 
  error
  
  
  partition - a partition of the observations is a way of sorting them into groups.
  factor - a meaningful partition of the observations. 
  
  Test for factors - observations in the partition groups have something in common?
    does it make sense to compare the means for the parition groups?
    if you interchange the groups of observations, does it affect the 
    interpretation of the data?
      
  factors in BF
    grand mean - bench mark 
    residual error
    treatment factor
    
  one factor is inside another if each group of the first factor fits completely 
  in the second factor.
  
  general decompostion rule
  
    observations = grand mean + company effect + residual errors
    
    estimated effect for a level of a factor = average for the level of the 
    factor - sum of effects for all outside factor
  
  df = number of levels for the factor - sum of df for all outside factors. 
  
   
  
    
  
  
  
  
  